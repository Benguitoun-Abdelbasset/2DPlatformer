{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f17671e0-dd5c-4264-98fe-146860dfa8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.35.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe_connected' \n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import matplotlib.pyplot as plt\n",
    "init_notebook_mode(connected=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f9514242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== DISPLAY ==========\n",
    "\n",
    "def plot_level(level, title=\"Generated Level\"):\n",
    "    level_2d = torch.tensor(level).reshape(15, 50)\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.imshow(level_2d, cmap=\"viridis\", aspect=\"auto\")\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9e869c51-9478-48b1-9dc9-f687642fef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tmx_level(tmx_file_path, map_shape=(1, 15, 50)):\n",
    "    \"\"\"\n",
    "    Loads a level from a .tmx file (in XML format with CSV encoding) into a PyTorch tensor.\n",
    "\n",
    "    Args:\n",
    "    - tmx_file_path (str): Path to the .tmx file\n",
    "    - map_shape (tuple): Shape of the tile map (channels, height, width)\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: Tensor of shape (1, 15, 50) or similar based on map_shape\n",
    "    \"\"\"\n",
    "    # Parse the XML file\n",
    "    tree = ET.parse(tmx_file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Find the data field in the XML structure\n",
    "    data_field = root.find(\".//layer/data[@encoding='csv']\")\n",
    "    if data_field is None:\n",
    "        raise ValueError(\"No CSV-encoded tile data found in this .tmx file.\")\n",
    "\n",
    "    # Get the CSV string of tile values\n",
    "    csv_data = data_field.text.strip()\n",
    "\n",
    "    # Convert the CSV string into a list of integers\n",
    "    tile_values = list(map(int, csv_data.split(',')))\n",
    "\n",
    "    # Reshape the tile values into the map shape (height, width)\n",
    "    height, width = map_shape[1], map_shape[2]\n",
    "    if len(tile_values) != height * width:\n",
    "        raise ValueError(f\"Tile data does not match the expected map size: {height}x{width}.\")\n",
    "    \n",
    "    # Convert to a numpy array and then to a PyTorch tensor\n",
    "    level = np.array(tile_values, dtype=np.int32).reshape((height, width))\n",
    "    level_tensor = torch.tensor(level, dtype=torch.long).unsqueeze(0)  # Add channel dimension\n",
    "\n",
    "    return level_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "675ae136-346a-47fc-8c5e-1f078f2b1321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_levels_from_folder(folder_path, map_shape=(1, 15, 50)):\n",
    "    \"\"\"\n",
    "    Loads all levels from a folder containing .tmx files into a list of PyTorch tensors.\n",
    "\n",
    "    Args:\n",
    "    - folder_path (str): Path to the folder containing .tmx files\n",
    "    - map_shape (tuple): Shape of the tile map (channels, height, width)\n",
    "\n",
    "    Returns:\n",
    "    - list of torch.Tensor: List of tensors, each representing a level\n",
    "    \"\"\"\n",
    "    # List all .tmx files in the directory\n",
    "    tmx_files = [f for f in os.listdir(folder_path) if f.endswith('.tmx')]\n",
    "    \n",
    "    # List to store all levels\n",
    "    all_levels = []\n",
    "\n",
    "    # Iterate through each .tmx file and load it\n",
    "    for tmx_file in tmx_files:\n",
    "        tmx_file_path = os.path.join(folder_path, tmx_file)\n",
    "        try:\n",
    "            # Load the level data from each .tmx file\n",
    "            level_tensor = load_tmx_level(tmx_file_path, map_shape)\n",
    "            all_levels.append(level_tensor)\n",
    "        except ValueError as e:\n",
    "            print(f\"Skipping {tmx_file}: {e}\")\n",
    "\n",
    "    return all_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4c66a718-0d76-4a5b-92ad-8baf69a9185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_shape=(1, 15, 50), latent_dim=256):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(latent_dim, 128 * 4 * 13),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.deconv = nn.Sequential(\n",
    "            # Start from 4×13 (after reshaping)\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), output_padding=(0, 0)),  # 8×26\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), output_padding=(0, 0)),   # 16×52\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, output_shape[0], kernel_size=(4, 5), padding=(1, 1), stride=(1, 1)),  # Reduced padding to get 15×50            nn.Softmax(dim=1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, 128, 4, 13)\n",
    "        x = self.deconv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d386cb18-2273-402a-a966-afd27d83f28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_channels, cond_dim):\n",
    "        super().__init__()\n",
    "        self.level_net = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.cond_net = nn.Sequential(\n",
    "            nn.Linear(cond_dim, 128),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        # Updated with correct flattened size for 15x50 input\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 3 * 12 + 128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x, cond):\n",
    "        x_feat = self.level_net(x)\n",
    "        cond_feat = self.cond_net(cond)\n",
    "        combined = torch.cat([x_feat, cond_feat], dim=1)\n",
    "        return self.fc(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9a15c52c-b1ba-40b2-845e-39dab66a7cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(generator, discriminator, dataloader, num_epochs, device):\n",
    "    g_opt = torch.optim.Adam(generator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "    d_opt = torch.optim.Adam(discriminator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "    loss_fn = nn.BCELoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for real_levels, cond_vecs in dataloader:\n",
    "            real_levels = real_levels.to(device)  # shape: [B, 1, 15, 50]\n",
    "            cond_vecs = cond_vecs.to(device)\n",
    "\n",
    "            batch_size = real_levels.size(0)\n",
    "            real_labels = torch.ones(batch_size, 1).to(device)\n",
    "            fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "            # -----------------------\n",
    "            # Train Discriminator\n",
    "            # -----------------------\n",
    "            z = torch.randn(batch_size, cond_vecs.shape[1]).to(device)\n",
    "            fake_levels = generator(z)\n",
    "\n",
    "            d_real = discriminator(real_levels, cond_vecs)\n",
    "            d_fake = discriminator(fake_levels.detach(), cond_vecs)\n",
    "\n",
    "            d_loss = loss_fn(d_real, real_labels) + loss_fn(d_fake, fake_labels)\n",
    "\n",
    "            d_opt.zero_grad()\n",
    "            d_loss.backward()\n",
    "            d_opt.step()\n",
    "\n",
    "            # -----------------------\n",
    "            # Train Generator\n",
    "            # -----------------------\n",
    "            g_fake = discriminator(fake_levels, cond_vecs)\n",
    "            g_loss = loss_fn(g_fake, real_labels)\n",
    "\n",
    "            g_opt.zero_grad()\n",
    "            g_loss.backward()\n",
    "            g_opt.step()\n",
    "\n",
    "        print(f\"[{epoch+1}/{num_epochs}] D_loss: {d_loss.item():.4f}, G_loss: {g_loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "63bd2817-8513-4719-9f6b-2e7eaee4e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_variable_type(variable):\n",
    "  var_type = type(variable)\n",
    "  if var_type is int:\n",
    "    print(f\"'{variable}' is an integer (which in Python 3 can represent 'long long' or '__int64').\")\n",
    "  elif var_type is float:\n",
    "    print(f\"'{variable}' is a float.\")\n",
    "  else:\n",
    "    print(f\"'{variable}' is of type: {var_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d737486d-a9ed-4985-892f-cb2fd45bfac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1303 levels.\n"
     ]
    }
   ],
   "source": [
    "#loading data\n",
    "folder_path = \"./2D game Project/good/\"\n",
    "levels = load_all_levels_from_folder(folder_path, map_shape=(1, 15, 50))\n",
    "\n",
    "# Check how many levels were loaded\n",
    "print(f\"Loaded {len(levels)} levels.\")\n",
    "\n",
    "\n",
    "float_levels = [level.float() for level in levels]\n",
    "\n",
    "stacked_levels = torch.stack(float_levels, dim=0)\n",
    "\n",
    "levels=stacked_levels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7e9466f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_test_generator(num_samples=10):\n",
    "    # Define the same parameters used during training\n",
    "    input_dim = 100\n",
    "    output_shape = (1, 15, 50)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Initialize a new generator with the same architecture\n",
    "    generator = Generator(input_dim=input_dim, output_shape=output_shape).to(device)\n",
    "    \n",
    "    # Load the saved state dictionary\n",
    "    generator.load_state_dict(torch.load('trained_generator.pth'))\n",
    "    \n",
    "    # Set to evaluation mode\n",
    "    generator.eval()\n",
    "    \n",
    "    # Generate samples\n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn(num_samples, input_dim, device=device)\n",
    "        generated_levels = generator(noise).cpu()\n",
    "        generated_levels_int = torch.round(generated_levels).int()\n",
    "    print(f\"Generated {num_samples} new level samples\")\n",
    "    return generated_levels_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2e5058d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n_plot():\n",
    "    generated_samples = load_and_test_generator(num_samples=1)\n",
    "    array = generated_samples[0].numpy()\n",
    "    array=np.maximum(array,0)\n",
    "    flattened_array = array.flatten()\n",
    "    comma_separated = ', '.join(map(str, flattened_array))\n",
    "    plot_level(flattened_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "392575d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_n_plot(level):\n",
    "    array = level[0].numpy()\n",
    "    array=np.maximum(array,0)\n",
    "    flattened_array = array.flatten()\n",
    "    comma_separated = ', '.join(map(str, flattened_array))\n",
    "    plot_level(flattened_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4cc370-b7a2-4971-95fe-e7d5ee7c6fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(generator, discriminator, levels, num_epochs=100, batch_size=16, \n",
    "              input_dim=100, cond_dim=1, lr=0.0002*0.4, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Train the GAN model.\n",
    "    \n",
    "    Args:\n",
    "        generator: The generator model\n",
    "        discriminator: The discriminator model\n",
    "        levels: List of real levels with shape [1, 15, 50]\n",
    "        num_epochs: Number of training epochs\n",
    "        batch_size: Batch size for training\n",
    "        input_dim: Dimension of the input noise vector\n",
    "        cond_dim: Dimension of the conditional input\n",
    "        lr: Learning rate\n",
    "        device: Device to train on ('cuda' or 'cpu')\n",
    "    \n",
    "    Returns:\n",
    "        Trained generator and discriminator\n",
    "    \"\"\"\n",
    "    \n",
    "    # Move models to device\n",
    "    generator = generator.to(device)\n",
    "    discriminator = discriminator.to(device)\n",
    "    \n",
    "    # Create dataset from levels list\n",
    "    levels_tensor = torch.stack(levels) if not isinstance(levels, torch.Tensor) else levels\n",
    "    # Create dummy conditions (modify as needed for your specific conditions)\n",
    "    dummy_conditions = torch.zeros(len(levels_tensor), cond_dim)\n",
    "    dataset = TensorDataset(levels_tensor, dummy_conditions)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    # Optimizers\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5*0.3, 0.999))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    \n",
    "    # Labels for real and fake\n",
    "    real_label = 1\n",
    "    fake_label = 0\n",
    "    \n",
    "    # Training loop\n",
    "    g_losses = []\n",
    "    d_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (real_levels, conditions) in enumerate(dataloader):\n",
    "            real_levels = real_levels.to(device)\n",
    "            conditions = conditions.to(device)\n",
    "            batch_size = real_levels.size(0)\n",
    "            \n",
    "            ############################\n",
    "            # Train Discriminator\n",
    "            ############################\n",
    "            # Real samples\n",
    "            optimizer_D.zero_grad()\n",
    "            output_real = discriminator(real_levels, conditions)\n",
    "            label_real = torch.full((batch_size, 1), real_label, device=device)\n",
    "            output_real=output_real.float()\n",
    "            label_real=label_real.float()\n",
    "            loss_real = criterion(output_real, label_real)\n",
    "            loss_real.backward()\n",
    "            \n",
    "            # Fake samples\n",
    "            noise = torch.randn(batch_size, input_dim, device=device)\n",
    "            fake_levels = generator(noise)\n",
    "            label_fake = torch.full((batch_size, 1), fake_label, device=device)\n",
    "            output_fake = discriminator(fake_levels.detach(), conditions)\n",
    "            output_fake=output_fake.float()\n",
    "            label_fake=label_fake.float()\n",
    "            loss_fake = criterion(output_fake, label_fake)\n",
    "            loss_fake.backward()\n",
    "            \n",
    "            # Update discriminator\n",
    "            loss_d = loss_real + loss_fake\n",
    "            optimizer_D.step()\n",
    "            \n",
    "            ############################\n",
    "            # Train Generator\n",
    "            ############################\n",
    "            optimizer_G.zero_grad()\n",
    "            # Generate fake samples again\n",
    "            output_fake = discriminator(fake_levels, conditions)\n",
    "            # Generator wants discriminator to think its outputs are real\n",
    "            loss_g = criterion(output_fake, label_real)\n",
    "            loss_g.backward()\n",
    "            optimizer_G.step()\n",
    "            \n",
    "            # Save losses for plotting\n",
    "            g_losses.append(loss_g.item())\n",
    "            d_losses.append(loss_d.item())\n",
    "        \n",
    "        # Print progress\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} | D Loss: {loss_d.item():.4f} | G Loss: {loss_g.item():.4f}\")\n",
    "            # Generate a sample to show progress\n",
    "            with torch.no_grad():\n",
    "                sample_noise = torch.randn(1, input_dim, device=device)\n",
    "                sample_level = generator(sample_noise).cpu()\n",
    "                sample_level_int = torch.round(sample_level).int()\n",
    "                # You can add visualization code here if needed\n",
    "                plot_level(sample_level_int)\n",
    "\n",
    "    \n",
    "    return generator, discriminator, g_losses, d_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "89650fde-9900-4d0a-b2ca-0b96ad2f82e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(num_epochs,batch_size):\n",
    "\n",
    "\n",
    "    \n",
    "    # Assuming you have these defined:\n",
    "    # - levels: list of real levels with shape [1, 15, 50]\n",
    "    # - input_dim: dimension of the input noise vector (e.g., 100)\n",
    "    # - Generator and Discriminator classes\n",
    "    \n",
    "    # Parameters\n",
    "    input_dim = 100\n",
    "    cond_dim = 1\n",
    "    output_shape = (1, 15, 50)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Initialize models\n",
    "    generator = Generator(input_dim=input_dim, output_shape=output_shape).to(device)\n",
    "    discriminator = Discriminator(input_channels=output_shape[0], cond_dim=cond_dim).to(device)\n",
    "    \n",
    "    # Train the GAN\n",
    "    generator, discriminator, g_losses, d_losses = train_gan(\n",
    "        generator,\n",
    "        discriminator, \n",
    "        levels,\n",
    "        num_epochs,\n",
    "        batch_size, \n",
    "        input_dim=input_dim,\n",
    "        cond_dim=cond_dim,\n",
    "        device=device\n",
    "    )\n",
    "    print(len(g_losses), len(d_losses))\n",
    "\n",
    "  # Create traces\n",
    "    trace1 = go.Scatter(y=g_losses, mode='lines', name='Generator Loss')\n",
    "    trace2 = go.Scatter(y=d_losses, mode='lines', name='Discriminator Loss')\n",
    "    \n",
    "    layout = go.Layout(title='GAN Training Loss', xaxis=dict(title='Iterations'), yaxis=dict(title='Loss'))\n",
    "    \n",
    "    fig = go.Figure(data=[trace1, trace2], layout=layout)\n",
    "    iplot(fig)\n",
    "\n",
    "    # Generate and save some samples\n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn(10, input_dim, device=device)\n",
    "        generated_levels = generator(noise).cpu()\n",
    "        \n",
    "        # Save the generator model\n",
    "        torch.save(generator.state_dict(), 'trained_generator.pth')\n",
    "        \n",
    "        print(\"Training complete. Generator saved as 'trained_generator.pth'\")\n",
    "        return generated_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ddf6129c-f0ed-4753-95bf-1bd0d8bc6eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100000 | D Loss: 1.4577 | G Loss: 0.7507\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100000\u001b[39m\n\u001b[0;32m      2\u001b[0m batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m\n\u001b[1;32m----> 4\u001b[0m generated_samples \u001b[38;5;241m=\u001b[39m run_training(num_epochs,batch_size)\n",
      "Cell \u001b[1;32mIn[56], line 21\u001b[0m, in \u001b[0;36mrun_training\u001b[1;34m(num_epochs, batch_size)\u001b[0m\n\u001b[0;32m     18\u001b[0m   discriminator \u001b[38;5;241m=\u001b[39m Discriminator(input_channels\u001b[38;5;241m=\u001b[39moutput_shape[\u001b[38;5;241m0\u001b[39m], cond_dim\u001b[38;5;241m=\u001b[39mcond_dim)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     20\u001b[0m   \u001b[38;5;66;03m# Train the GAN\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m   generator, discriminator, g_losses, d_losses \u001b[38;5;241m=\u001b[39m train_gan(\n\u001b[0;32m     22\u001b[0m       generator,\n\u001b[0;32m     23\u001b[0m       discriminator, \n\u001b[0;32m     24\u001b[0m       levels,\n\u001b[0;32m     25\u001b[0m       num_epochs,\n\u001b[0;32m     26\u001b[0m       batch_size, \n\u001b[0;32m     27\u001b[0m       input_dim\u001b[38;5;241m=\u001b[39minput_dim,\n\u001b[0;32m     28\u001b[0m       cond_dim\u001b[38;5;241m=\u001b[39mcond_dim,\n\u001b[0;32m     29\u001b[0m       device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[0;32m     30\u001b[0m   )\n\u001b[0;32m     31\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(g_losses), \u001b[38;5;28mlen\u001b[39m(d_losses))\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Create traces\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[55], line 102\u001b[0m, in \u001b[0;36mtrain_gan\u001b[1;34m(generator, discriminator, levels, num_epochs, batch_size, input_dim, cond_dim, lr, device)\u001b[0m\n\u001b[0;32m    100\u001b[0m             sample_level \u001b[38;5;241m=\u001b[39m generator(sample_noise)\n\u001b[0;32m    101\u001b[0m             \u001b[38;5;66;03m# You can add visualization code here if needed\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m             clean_n_plot(sample_noise)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m generator, discriminator, g_losses, d_losses\n",
      "Cell \u001b[1;32mIn[54], line 2\u001b[0m, in \u001b[0;36mclean_n_plot\u001b[1;34m(level)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclean_n_plot\u001b[39m(level):\n\u001b[1;32m----> 2\u001b[0m     array \u001b[38;5;241m=\u001b[39m level[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      3\u001b[0m     array\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmaximum(array,\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      4\u001b[0m     flattened_array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mflatten()\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "num_epochs=100000\n",
    "batch_size=128\n",
    "\n",
    "generated_samples = run_training(num_epochs,batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b94d5a-c1ac-4009-b3b1-bf55483daa79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# input_dim = 100\n",
    "# generator = Generator(input_dim=input_dim, output_shape=(1, 15, 50))\n",
    "\n",
    "# latent_vector = torch.randn(1, input_dim)  # Batch size of 1\n",
    "# generated_level = generator(latent_vector)\n",
    "\n",
    "# # Check the shape of the generated level\n",
    "# print(\"Generated level shape:\", generated_level.shape)\n",
    "\n",
    "\n",
    "# cond_dim_placeholder = 1\n",
    "# dummy_conditions = torch.zeros(batch_size, cond_dim_placeholder)\n",
    "\n",
    "# # Pass the dummy data through the discriminator\n",
    "\n",
    "# discriminator = Discriminator(1, 1)\n",
    "\n",
    "# output = discriminator(generated_level, dummy_conditions)\n",
    "\n",
    "# # Print the output shape\n",
    "# print(\"Discriminator Output Shape:\", output.shape)\n",
    "\n",
    "# # You can also print the output values to see the predictions\n",
    "# print(\"Discriminator Output Values (probabilities):\")\n",
    "# plot_level(output)\n",
    "\n",
    "\n",
    "# #gan = train_gan(generator, discriminator, dataloader, num_epochs, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
